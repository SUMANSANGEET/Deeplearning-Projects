{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Step 1: Generate Dummy Data\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(1000, 10)  # 1000 samples, 10 features\n",
        "y = np.random.randint(0, 2, size=1000)  # Binary classification (0 or 1)\n",
        "\n",
        "# Step 2: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Build ANN Model\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "# Step 5: Generate Predictions\n",
        "proba = model.predict(X_test).flatten()  # Probabilities\n",
        "predictions = (proba > 0.5).astype(int)  # Threshold at 0.5 for binary classification\n",
        "max_proba = np.max(proba)  # For example purposes, showing the max probability\n",
        "\n",
        "# Step 6: Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Max_proba': proba,\n",
        "    'Index': np.arange(len(proba)),\n",
        "    'Prediction_class': predictions,\n",
        "    'Ground_Truth_class': y_test,\n",
        "    'Output': np.where(predictions == y_test, 'Correct', 'Incorrect')  # Compare predictions\n",
        "})\n",
        "\n",
        "# Step 7: Calculate Metrics\n",
        "# True Positives, False Positives, True Negatives, False Negatives\n",
        "TP = np.sum((predictions == 1) & (y_test == 1))\n",
        "FP = np.sum((predictions == 1) & (y_test == 0))\n",
        "TN = np.sum((predictions == 0) & (y_test == 0))\n",
        "FN = np.sum((predictions == 0) & (y_test == 1))\n",
        "\n",
        "# Accuracy\n",
        "accuracy = (TP + TN) / len(y_test)\n",
        "\n",
        "# Precision\n",
        "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "\n",
        "# Recall\n",
        "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "# F1-Score\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "# Print Results\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1_score)\n",
        "\n",
        "# Display DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxazQgegP_Rx",
        "outputId": "82f0f4e1-6af7-405f-b7d9-f72c039d9228"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "Accuracy: 0.52\n",
            "Precision: 0.5126582278481012\n",
            "Recall: 0.81\n",
            "F1-Score: 0.627906976744186\n",
            "   Max_proba  Index  Prediction_class  Ground_Truth_class     Output\n",
            "0   0.524351      0                 1                   0  Incorrect\n",
            "1   0.505799      1                 1                   1    Correct\n",
            "2   0.489135      2                 0                   1  Incorrect\n",
            "3   0.525471      3                 1                   1    Correct\n",
            "4   0.526972      4                 1                   1    Correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import Necessary Libraries:**"
      ],
      "metadata": {
        "id": "bu78bjJcQNT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "_sEofW-6QU3Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Load and Preprocess the Data:**"
      ],
      "metadata": {
        "id": "zjXN3bALQshm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.rand(1000, 10)  # 1000 samples, 10 features\n",
        "y = np.random.randint(0, 2, size=1000)  # Binary classification (0 or 1)"
      ],
      "metadata": {
        "id": "uh1O9qDZQxSG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Train/Test Split:**"
      ],
      "metadata": {
        "id": "lD_i4K3lRKlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Gdfkbe36RPR6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Build the ANN model**"
      ],
      "metadata": {
        "id": "blqVnYY6Ra3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "I2Wa-RGlRaWx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Train the Model:**"
      ],
      "metadata": {
        "id": "rWHynMfiRwRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdi4IPmeR8eG",
        "outputId": "3d3762d7-19ba-44a4-c731-1e7d9590bd33"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aa8d17d0bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Make Predictions:**"
      ],
      "metadata": {
        "id": "PeV4kv6ESORx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proba = model.predict(X_test).flatten()  # Probabilities\n",
        "predictions = (proba > 0.5).astype(int)  # Threshold at 0.5 for binary classification\n",
        "max_proba = np.max(proba)  # For example purposes, showing the max probability"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C4jxdH5SPu_",
        "outputId": "6fb56e5a-c3b6-434e-d45b-52b3d54281c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 321 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7aa8ea1a4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Create Dataframe**"
      ],
      "metadata": {
        "id": "INc3PhIsSh8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    'Max_proba': proba,\n",
        "    'Index': np.arange(len(proba)),\n",
        "    'Prediction_class': predictions,\n",
        "    'Ground_Truth_class': y_test,\n",
        "    'Output': np.where(predictions == y_test, 'Correct', 'Incorrect')  # Compare predictions\n",
        "})"
      ],
      "metadata": {
        "id": "jJEXl6hJShdX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Calculate Metrics**"
      ],
      "metadata": {
        "id": "VJSXpsS5S4Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# True Positives, False Positives, True Negatives, False Negatives\n",
        "TP = np.sum((predictions == 1) & (y_test == 1))\n",
        "FP = np.sum((predictions == 1) & (y_test == 0))\n",
        "TN = np.sum((predictions == 0) & (y_test == 0))\n",
        "FN = np.sum((predictions == 0) & (y_test == 1))\n",
        "# Accuracy\n",
        "accuracy = (TP + TN) / len(y_test)\n",
        "\n",
        "# Precision\n",
        "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "\n",
        "# Recall\n",
        "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "# F1-Score\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0"
      ],
      "metadata": {
        "id": "EXdOxo6dS306"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.Print Results:**"
      ],
      "metadata": {
        "id": "qAudnWScTfYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk5I94OSTRCl",
        "outputId": "f20c4140-9bc9-48e1-9c96-4054850b375a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.535\n",
            "Precision: 0.5228758169934641\n",
            "Recall: 0.8\n",
            "F1-Score: 0.6324110671936759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Dataframe**"
      ],
      "metadata": {
        "id": "YCKJkF6KTpr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wN4jVmFX1xa",
        "outputId": "bc38ee51-516c-49ed-de6b-3bb9ff30f925"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Max_proba  Index  Prediction_class  Ground_Truth_class     Output\n",
            "0   0.532007      0                 1                   0  Incorrect\n",
            "1   0.477396      1                 0                   1  Incorrect\n",
            "2   0.485973      2                 0                   1  Incorrect\n",
            "3   0.508992      3                 1                   1    Correct\n",
            "4   0.541290      4                 1                   1    Correct\n"
          ]
        }
      ]
    }
  ]
}